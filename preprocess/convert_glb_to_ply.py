"""
GLB to PLY Point Cloud Converter for DepthAnything V3

This script converts point cloud data from GLB format (generated by DepthAnything V3)
to PLY format for use in 3DGS training pipelines.

DepthAnything V3 can export 3D point clouds in GLB format, which need to be converted
to PLY format compatible with COLMAP/S-3DGS workflows.

Features:
- Loads GLB files containing point clouds or mesh vertices
- Extracts vertex positions and colors
- Handles both PointCloud and Trimesh geometries
- Supports downsampling to target point count
- Outputs standard PLY format with RGB colors

Author: Integration for DepthAnything V3
Date: 2025-01-21
"""

import numpy as np
import trimesh
from plyfile import PlyData, PlyElement
import os
import argparse
from typing import Tuple, Optional
import warnings


def load_glb_point_cloud(glb_path: str) -> Tuple[np.ndarray, np.ndarray]:
    """
    Load point cloud data from GLB file.

    Args:
        glb_path: Path to input GLB file

    Returns:
        points: Nx3 array of vertex positions
        colors: Nx3 array of RGB colors (uint8)

    Raises:
        ValueError: If no point data found in GLB file
    """
    print(f"Loading GLB: {glb_path}...")

    if not os.path.exists(glb_path):
        raise FileNotFoundError(f"GLB file not found: {glb_path}")

    scene = trimesh.load(glb_path)

    # GLB usually loads as a Scene, composed of Meshes or PointClouds
    points = []
    colors = []

    # Extract geometry
    if isinstance(scene, trimesh.Scene):
        for name, geom in scene.geometry.items():
            if isinstance(geom, trimesh.PointCloud):
                # Direct point cloud
                points.append(geom.vertices)
                if geom.colors is not None:
                    colors.append(geom.colors)
                else:
                    # Default gray for point clouds without colors
                    colors.append(np.full((len(geom.vertices), 3), 128, dtype=np.uint8))

            elif isinstance(geom, trimesh.Trimesh):
                # Fallback if DA3 exported mesh vertices instead of points
                points.append(geom.vertices)
                # Trimesh colors are usually visual.vertex_colors
                if geom.visual.vertex_colors is not None:
                    colors.append(geom.visual.vertex_colors[:, :3])  # Keep RGB only
                else:
                    # Default gray for meshes without colors
                    colors.append(np.full((len(geom.vertices), 3), 128, dtype=np.uint8))

    elif isinstance(scene, trimesh.PointCloud):
        # Single point cloud (not wrapped in Scene)
        points.append(scene.vertices)
        if scene.colors is not None:
            colors.append(scene.colors)
        else:
            colors.append(np.full((len(scene.vertices), 3), 128, dtype=np.uint8))

    elif isinstance(scene, trimesh.Trimesh):
        # Single mesh (not wrapped in Scene)
        points.append(scene.vertices)
        if scene.visual.vertex_colors is not None:
            colors.append(scene.visual.vertex_colors[:, :3])
        else:
            colors.append(np.full((len(scene.vertices), 3), 128, dtype=np.uint8))

    else:
        raise ValueError(f"Unsupported geometry type: {type(scene)}")

    if not points:
        raise ValueError("No point data found in GLB file.")

    # Combine all geometries
    all_points = np.vstack(points)

    if colors:
        all_colors = np.vstack(colors)
    else:
        # Default gray if no colors found
        all_colors = np.full((all_points.shape[0], 3), 128, dtype=np.uint8)

    # Normalize colors to 0-255 uint8 range
    if all_colors.dtype == np.float32 or all_colors.dtype == np.float64:
        if all_colors.max() <= 1.0:
            all_colors = (all_colors * 255).astype(np.uint8)
        else:
            all_colors = all_colors.astype(np.uint8)

    # Ensure we only have RGB channels (drop Alpha if present)
    if all_colors.shape[1] > 3:
        all_colors = all_colors[:, :3]

    print(f"  Loaded {all_points.shape[0]} points with colors")

    return all_points, all_colors


def downsample_points(
    points: np.ndarray,
    colors: np.ndarray,
    target_count: int,
    method: str = 'random'
) -> Tuple[np.ndarray, np.ndarray]:
    """
    Downsample point cloud to target count.

    Args:
        points: Nx3 array of vertex positions
        colors: Nx3 array of RGB colors
        target_count: Target number of points
        method: Downsampling method ('random' or 'voxel')

    Returns:
        downsampled_points: target_countx3 array
        downsampled_colors: target_countx3 array
    """
    n_points = points.shape[0]

    if n_points <= target_count:
        print(f"  No downsampling needed ({n_points} < {target_count})")
        return points, colors

    print(f"  Downsampling from {n_points} to ~{target_count} points (method: {method})...")

    if method == 'random':
        # Random sampling (simplest approach)
        indices = np.random.choice(n_points, target_count, replace=False)
        downsampled_points = points[indices]
        downsampled_colors = colors[indices]

    elif method == 'voxel':
        # Voxel grid filtering (better spatial distribution)
        voxel_size = (n_points / target_count) ** (1/3) * np.ptp(points, axis=0).mean() / n_points**(1/3)

        # Simple voxel-based downsampling
        # Compute voxel indices for each point
        voxel_indices = np.floor(points / voxel_size).astype(np.int32)

        # Use unique voxels and pick one point per voxel
        _, unique_indices = np.unique(voxel_indices, axis=0, return_index=True)

        # If still too many, randomly sample
        if len(unique_indices) > target_count:
            selected_indices = np.random.choice(
                len(unique_indices),
                target_count,
                replace=False
            )
            unique_indices = unique_indices[selected_indices]

        downsampled_points = points[unique_indices]
        downsampled_colors = colors[unique_indices]

    else:
        raise ValueError(f"Unknown downsampling method: {method}")

    print(f"  Downsampled to {downsampled_points.shape[0]} points")

    return downsampled_points, downsampled_colors


def save_ply(points: np.ndarray, colors: np.ndarray, output_path: str):
    """
    Save point cloud as PLY file.

    Args:
        points: Nx3 array of vertex positions
        colors: Nx3 array of RGB colors (uint8)
        output_path: Path to output PLY file
    """
    print(f"Saving PLY: {output_path}...")

    # Create output directory if needed
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)

    # Construct structured array for PlyData
    # x, y, z, red, green, blue
    vertices = np.empty(len(points), dtype=[
        ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),
        ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')
    ])

    vertices['x'] = points[:, 0]
    vertices['y'] = points[:, 1]
    vertices['z'] = points[:, 2]
    vertices['red'] = colors[:, 0]
    vertices['green'] = colors[:, 1]
    vertices['blue'] = colors[:, 2]

    # Write PLY file (binary format for efficiency)
    ply_el = PlyElement.describe(vertices, 'vertex')
    PlyData([ply_el], text=False).write(output_path)

    print(f"  Saved {len(points)} points to {output_path}")


def convert_glb_to_ply(
    glb_path: str,
    output_path: str,
    target_count: Optional[int] = None,
    downsample_method: str = 'random',
    seed: Optional[int] = None
):
    """
    Convert GLB point cloud to PLY format.

    Args:
        glb_path: Path to input GLB file
        output_path: Path to output PLY file
        target_count: Target point count for downsampling (None to keep all)
        downsample_method: Method for downsampling ('random' or 'voxel')
        seed: Random seed for reproducibility (None for random)
    """
    if seed is not None:
        np.random.seed(seed)
        print(f"Random seed set to {seed}")

    try:
        # Load GLB
        points, colors = load_glb_point_cloud(glb_path)

        # Downsample if requested
        if target_count is not None and points.shape[0] > target_count:
            points, colors = downsample_points(points, colors, target_count, downsample_method)

        # Save as PLY
        save_ply(points, colors, output_path)

        print("✓ Conversion successful!")
        print(f"  Input:  {glb_path}")
        print(f"  Output: {output_path}")
        print(f"  Points: {points.shape[0]}")

    except Exception as e:
        print(f"✗ Conversion failed: {e}")
        raise


def verify_ply(ply_path: str):
    """
    Verify PLY file by loading and checking properties.

    Args:
        ply_path: Path to PLY file
    """
    print(f"\nVerifying PLY: {ply_path}...")

    try:
        ply_data = PlyData.read(ply_path)
        vertex = ply_data['vertex']

        n_points = len(vertex)
        points = np.vstack([vertex['x'], vertex['y'], vertex['z']]).T
        colors = np.vstack([vertex['red'], vertex['green'], vertex['blue']]).T

        print(f"  Points: {n_points}")
        print(f"  XYZ range: [{points.min():.2f}, {points.max():.2f}]")
        print(f"  RGB range: [{colors.min()}, {colors.max()}]")
        print("  ✓ PLY file is valid")

    except Exception as e:
        print(f"  ✗ PLY verification failed: {e}")


def main():
    parser = argparse.ArgumentParser(
        description='Convert DepthAnything V3 GLB point clouds to PLY format'
    )
    parser.add_argument(
        'glb_path',
        type=str,
        help='Path to input GLB file'
    )
    parser.add_argument(
        'output_path',
        type=str,
        help='Path to output PLY file'
    )
    parser.add_argument(
        '--target_count',
        type=int,
        default=500000,
        help='Target point count for downsampling (default: 500000, use -1 to keep all)'
    )
    parser.add_argument(
        '--method',
        type=str,
        choices=['random', 'voxel'],
        default='random',
        help='Downsampling method (default: random)'
    )
    parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='Random seed for reproducibility (default: None)'
    )
    parser.add_argument(
        '--verify',
        action='store_true',
        help='Verify output PLY file after conversion'
    )

    args = parser.parse_args()

    # Handle -1 as "keep all points"
    target_count = None if args.target_count == -1 else args.target_count

    print("="*60)
    print("GLB to PLY Converter - DepthAnything V3")
    print("="*60)

    convert_glb_to_ply(
        glb_path=args.glb_path,
        output_path=args.output_path,
        target_count=target_count,
        downsample_method=args.method,
        seed=args.seed
    )

    if args.verify:
        verify_ply(args.output_path)

    print("="*60)
    print("Done!")
    print("="*60)


if __name__ == "__main__":
    # Example usage:
    # python preprocess/convert_glb_to_ply.py input.glb output.ply --target_count 500000 --verify

    # Or run with default paths (modify these for your setup)
    # Example:
    #   python preprocess/convert_glb_to_ply.py \
    #       D:\PythonProject\data\da3_pointcloud.glb \
    #       D:\PythonProject\data\dense_init.ply \
    #       --target_count 500000 \
    #       --verify

    main()
